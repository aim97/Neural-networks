{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_ds(csv_file, img_sz):\n",
    "    df = pd.read_csv(csv_file).values\n",
    "    n = df.shape[0]\n",
    "    h, w = img_sz\n",
    "    train_labels = df[:, 0]\n",
    "    train_images = df[:, 1:].reshape((n, h, w, 1))\n",
    "    return train_images, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 42000 records in the dataset\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_images, training_labels = read_ds('./digit-recognizer/train.csv', (28, 28))\n",
    "\n",
    "print('we have {} records in the dataset'.format(training_labels.shape[0]))\n",
    "plt.imshow(training_images[0].reshape(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "training_images = training_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = tf.keras.Sequential([\n",
    "    Conv2D(64, (3,3), input_shape=(28, 28, 1)), # 26\n",
    "    MaxPool2D(), # 13\n",
    "    Conv2D(32, (3,3)), # 11\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=tf.nn.relu),\n",
    "    Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.1651 - accuracy: 0.9486\n",
      "Epoch 2/50\n",
      "1313/1313 [==============================] - 34s 26ms/step - loss: 0.0508 - accuracy: 0.9846\n",
      "Epoch 3/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0345 - accuracy: 0.9888\n",
      "Epoch 4/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0266 - accuracy: 0.9917\n",
      "Epoch 5/50\n",
      "1313/1313 [==============================] - 32s 25ms/step - loss: 0.0205 - accuracy: 0.9932\n",
      "Epoch 6/50\n",
      "1313/1313 [==============================] - 32s 25ms/step - loss: 0.0177 - accuracy: 0.9942\n",
      "Epoch 7/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0142 - accuracy: 0.9950\n",
      "Epoch 8/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0133 - accuracy: 0.9955\n",
      "Epoch 9/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0117 - accuracy: 0.9961\n",
      "Epoch 10/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0120 - accuracy: 0.9964\n",
      "Epoch 11/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0106 - accuracy: 0.9969\n",
      "Epoch 12/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0082 - accuracy: 0.9976\n",
      "Epoch 13/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0086 - accuracy: 0.9976\n",
      "Epoch 14/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0096 - accuracy: 0.9972\n",
      "Epoch 15/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0080 - accuracy: 0.9978\n",
      "Epoch 16/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 17/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0113 - accuracy: 0.9968\n",
      "Epoch 18/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0075 - accuracy: 0.9976\n",
      "Epoch 19/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0068 - accuracy: 0.9981\n",
      "Epoch 20/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0078 - accuracy: 0.9977\n",
      "Epoch 21/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0095 - accuracy: 0.9976\n",
      "Epoch 22/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "Epoch 23/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0103 - accuracy: 0.9978\n",
      "Epoch 24/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0088 - accuracy: 0.9979\n",
      "Epoch 25/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0087 - accuracy: 0.9980\n",
      "Epoch 26/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0073 - accuracy: 0.9981\n",
      "Epoch 27/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0056 - accuracy: 0.9986\n",
      "Epoch 28/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0082 - accuracy: 0.9982\n",
      "Epoch 29/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0057 - accuracy: 0.9986\n",
      "Epoch 30/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0074 - accuracy: 0.9982\n",
      "Epoch 31/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0109 - accuracy: 0.9979\n",
      "Epoch 32/50\n",
      "1313/1313 [==============================] - 32s 25ms/step - loss: 0.0043 - accuracy: 0.9989\n",
      "Epoch 33/50\n",
      "1313/1313 [==============================] - 32s 25ms/step - loss: 0.0066 - accuracy: 0.9985\n",
      "Epoch 34/50\n",
      "1313/1313 [==============================] - 32s 25ms/step - loss: 0.0095 - accuracy: 0.9980\n",
      "Epoch 35/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0068 - accuracy: 0.9985\n",
      "Epoch 36/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "Epoch 37/50\n",
      "1313/1313 [==============================] - 32s 25ms/step - loss: 0.0086 - accuracy: 0.9984\n",
      "Epoch 38/50\n",
      "1313/1313 [==============================] - 32s 25ms/step - loss: 0.0081 - accuracy: 0.9982\n",
      "Epoch 39/50\n",
      "1313/1313 [==============================] - 32s 25ms/step - loss: 0.0061 - accuracy: 0.9989\n",
      "Epoch 40/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 41/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0088 - accuracy: 0.9983\n",
      "Epoch 42/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0084 - accuracy: 0.9984\n",
      "Epoch 43/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0074 - accuracy: 0.9988\n",
      "Epoch 44/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0068 - accuracy: 0.9986\n",
      "Epoch 45/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0143 - accuracy: 0.9978\n",
      "Epoch 46/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0056 - accuracy: 0.9988\n",
      "Epoch 47/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0041 - accuracy: 0.9993\n",
      "Epoch 48/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0115 - accuracy: 0.9980\n",
      "Epoch 49/50\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "Epoch 50/50\n",
      "  23/1313 [..............................] - ETA: 30s - loss: 0.0429 - accuracy: 0.9959"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x = training_images,\n",
    "    y = training_labels,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 10)\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_df = pd.read_csv('./digit-recognizer/test.csv').values\n",
    "test_images = test_df.reshape((test_df.shape[0], 28, 28, 1))\n",
    "\n",
    "out = model.predict(test_images)\n",
    "\n",
    "print(out.shape)\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 9 ... 3 9 2]\n"
     ]
    }
   ],
   "source": [
    "labels = np.argmax(out, axis=1)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1     2]\n",
      " [    2     0]\n",
      " [    3     9]\n",
      " ...\n",
      " [27998     3]\n",
      " [27999     9]\n",
      " [28000     2]]\n"
     ]
    }
   ],
   "source": [
    "imageIds = np.arange(1, labels.shape[0]+1, 1)\n",
    "results = np.array([imageIds, labels]).T\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ImageId  Label\n",
      "0            1      2\n",
      "1            2      0\n",
      "2            3      9\n",
      "3            4      9\n",
      "4            5      3\n",
      "...        ...    ...\n",
      "27995    27996      9\n",
      "27996    27997      7\n",
      "27997    27998      3\n",
      "27998    27999      9\n",
      "27999    28000      2\n",
      "\n",
      "[28000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=['ImageId','Label'])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "results_df.to_csv('out.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}