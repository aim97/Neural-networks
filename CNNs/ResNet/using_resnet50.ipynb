{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUkccX0vK3YUN2ZCH+uLmO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aim97/Neural-networks/blob/master/CNNs/ResNet/using_resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOR_PzGRjByM"
      },
      "source": [
        "# Using Resnet 50\n",
        "\n",
        "This demo shows how to use Resnet 50, as well as some considerations needed while writting your code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKNJCT4z1XUn"
      },
      "source": [
        "# load necessary libraries\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D29wjSN5jyuG"
      },
      "source": [
        "For the purposes of this demo we will use Resent50 model without pre trained weights, so\n",
        "```\n",
        "weights = None\n",
        "```\n",
        "We will use MNIST data set for digit recognition, which has 10 classes, in transfer learning process, we usually would remove the top layer at least and add our own, but we will simply incldue the top layer of this model but have 10 classes.\n",
        "```\n",
        "include_top=true\n",
        "```\n",
        "Since we included the top, we have to tell the model the model what activation to use.\n",
        "```\n",
        "classifier_activation='softmax'\n",
        "```\n",
        "We have a little problem here, MNIST dataset images are all, 28x28, RESNET input should at least be 32x32, so we will rescale our images to the minimum expected by the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9tC2dJA2rfy"
      },
      "source": [
        "# load trained model\n",
        "# For now we don't want a trained model we just want the network\n",
        "image_shape = (32, 32, 1)\n",
        "model = tf.keras.applications.resnet50.ResNet50(\n",
        "  # weights='imagenet',\n",
        "  weights=None,\n",
        "  include_top=True,\n",
        "  classes=10,\n",
        "  classifier_activation='softmax',\n",
        "  input_shape=image_shape\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RVv2JAU1uHh"
      },
      "source": [
        "# load data from keras datasets\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "assert x_train.shape == (60000, 28, 28)\n",
        "assert x_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-TUqOwn6dld",
        "outputId": "3683042c-cf4c-4157-d0ea-78ac72888479"
      },
      "source": [
        "# this preporcessing is required by all resent networks and it's easy to apply.\n",
        "def preprocess(imgs, image_shape):\n",
        "  # apply resent preprocessing\n",
        "  shape = imgs.shape\n",
        "  x = tf.keras.applications.resnet50.preprocess_input(imgs)\n",
        "  # add an additional channel\n",
        "  x = x.reshape(shape + (1, ))\n",
        "  # resize the image\n",
        "  x = tf.image.resize(x, image_shape[:-1])\n",
        "  # normalize image pixels\n",
        "  x /= 255.0\n",
        "  return x\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "x_train = preprocess(x_train, image_shape)\n",
        "x_test = preprocess(x_test, image_shape)\n",
        "# x_train = tf.image.resize(preprocess(x_train).reshape(x_train.shape + (1,) ), image_shape[:-1]) / 255.0\n",
        "# x_test  = tf.image.resize(preprocess(x_test).reshape(x_test.shape + (1,) ), image_shape[:-1]) / 255.0\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000, 32, 32, 1)\n",
            "(10000, 32, 32, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyvhCXGgrVSn"
      },
      "source": [
        "From this point onwards we proceed normally, we compile the model, then train it on the data we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsOr-w0V7Y7_"
      },
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVAGIy6OteiK"
      },
      "source": [
        "# Danger\n",
        "If you try to run this model it will take a long time for training and won't reach a good result on this problem:\n",
        "\n",
        "## Why\n",
        "\n",
        "1. The simplicity of Digit recognition, so a small model will work fine on it. (we only use MNIST since it's just a demo).\n",
        "2. **Resnet50 has a large number of layers**, too many parameters to train, so it naturally takes long regardless of the application (it depends on the machine of course), so *you should only try a large network once you decided that you actually need one*, otherwise doing so would be a waste of time.\n",
        "3. After running the model for about two hours, it only finished 2 epochs with accurcy 96%, which is close but not better than smaller models, which makes sense, Resnet is made to make sure adding more layers doesn't hurt performance but it doesn't necerssarily improve it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WErqbG5m6_7f",
        "outputId": "11a2f5d5-a1b3-44b2-bb15-8be1db407609"
      },
      "source": [
        "model.fit(x=x_train, y=y_train, batch_size=32, epochs=4)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "1875/1875 [==============================] - 3325s 2s/step - loss: 0.4113 - accuracy: 0.9072\n",
            "Epoch 2/4\n",
            "1875/1875 [==============================] - 4562s 2s/step - loss: 0.1561 - accuracy: 0.9648\n",
            "Epoch 3/4\n",
            "1875/1875 [==============================] - 4399s 2s/step - loss: 0.2320 - accuracy: 0.9452\n",
            "Epoch 4/4\n",
            "1875/1875 [==============================] - 4304s 2s/step - loss: 0.1550 - accuracy: 0.9620\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fca41510190>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}