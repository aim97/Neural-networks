{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Callbacks\n",
    "\n",
    "often you may want to do something with your model at some point during training, for example save the model, stop training, change the learning rate, etc. if you were writing your own training loop, you could add the functions you want to call at each step, but since you are using a fit function provided by Tensorflow you can't do that. in return Tensorflow provides away to achieve this goal with callbacks.\n",
    "\n",
    "Callbacks are objects extending the `tf.keras.callbacks.Callback` class. They are passed to the `fit` function (or any function that operates the model e.g. `evaluate` or `predict`), they include a set of methods to be called when certain events occur during training.\n",
    "\n",
    "## Events of interest\n",
    "\n",
    "For each event you want to execute the call back must implement a method with the same name as the event, for example `on_epoch_end` for the `epoch_end` event.\n",
    "\n",
    "### Global methods\n",
    "\n",
    "1. `on_(train|test|predict)_begin(self, logs=None)`: Called at the beginning of fit/evaluate/predict.\n",
    "2. `on_(train|test|predict)_end(self, logs=None)`: Called at the end of fit/evaluate/predict.\n",
    "\n",
    "### Batch-level methods for training/testing/predicting\n",
    "\n",
    "1. `on_(train|test|predict)_batch_begin(self, batch, logs=None)`: Called right before processing a batch during training/testing/predicting.\n",
    "2. `on_(train|test|predict)_batch_end(self, batch, logs=None)`: Called at the end of training/testing/predicting a batch. Within this method, logs is a dict containing the metrics results.\n",
    "\n",
    "### Epoch-level methods (training only) **Most used**\n",
    "\n",
    "1. `on_epoch_begin(self, epoch, logs=None)`: Called at the beginning of an epoch during training.\n",
    "2. `on_epoch_end(self, epoch, logs=None)`: Called at the end of an epoch during training.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Built-in callbacks\n",
    "\n",
    "Tensorflow provides a set of built-in callbacks that you can use to control the training process, for example:\n",
    "\n",
    "1. `tf.keras.callbacks.EarlyStopping`: Stops training when a monitored quantity has stopped improving.\n",
    "2. `tf.keras.callbacks.ModelCheckpoint`: Saves the model after every epoch.\n",
    "3. `tf.keras.callbacks.TensorBoard`: Writes summary data to Tensorboard.\n",
    "4. `tf.keras.callbacks.ReduceLROnPlateau`: Reduces the learning rate when a metric has stopped improving.\n",
    "\n",
    "And more, you can find a complete list of callbacks in the [Tensorflow documentation](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback).\n",
    "\n",
    "\n",
    "### Using a callback\n",
    "\n",
    "You tell tensorflow to call the callbacks you want from the `callbacks` parameter in functions like `fit`, `evaluate` or `predict`.\n",
    "\n",
    "```python\n",
    "my_callback = customCallBack()\n",
    "stopEarly = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit( ..., callbacks=[my_callback, stopEarly]) # you pass the object not the class\n",
    "```\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Early stopping and Model ModelCheckpoint callbacks\n",
    "\n",
    "Early stopping is a callback that stops training when a monitored quantity has stopped improving, and ModelCheckpoint is a callback that saves the model after every epoch.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tensorboard callback"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom callbacks\n",
    "\n",
    "At somepoint you may want to carry out operations that no builtin callback would do for you, like certain plots, or event some logs, for that you can extend the `tf.keras.callbacks.Callback` class yourself to implement your own callbacks.\n",
    "\n",
    "```python\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "  # define the events of interest here\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    # do something at the end of each epoch\n",
    "```\n",
    "\n",
    "Of course you might wonder, how on earth can you for example test the model with a callback, save the weights, keep track of the loss, etc. if you have no access to them, as you see the event function always takes epoch or batch number, and some logs.\n",
    "\n",
    "**Logs**: it's a dictionary with the metrics results after the last batch or epoch, and it's useful for keeping track of the mertics.\n",
    "\n",
    "to access the model itself you can use the `model` attribute like `self.model` inside the callback, this enables you to stop the training, save the weights, change the learning rate, or even use the model right away to see how well it's doing.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom callback: TestingPlotCallback\n",
    "\n",
    "it's allows me to display the testing results during training after each `epoch_step` epochs, it extends `PlottingCallback` which initializes the figure and subplots, then the `on_epoch_end` method is called after each epoch to fill the subplots.\n",
    "\n",
    "It was mainly used for demo purposes, but would need some update to work more generally."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from math import floor\n",
    "\n",
    "class PlottingCallback:\n",
    "  def __init__(self, epochs_step, steps, title):\n",
    "    super(PlottingCallback, self).__init__()\n",
    "    self.epochs_step = epochs_step\n",
    "    self.steps = steps\n",
    "\n",
    "    # we will draw a number of subplots depending on the `steps` parameter\n",
    "    # so we use it to compute the rows and columns for the subplots grid\n",
    "    rows = (steps + 4) // 5\n",
    "    cols = 5\n",
    "\n",
    "    self.fig, self.plots = plt.subplots(rows, cols, figsize=(17, rows * 3))\n",
    "    self.fig.suptitle(title, fontsize=15, color='forestgreen')\n",
    "\n",
    "    # make sure to leave some padding between the subplots\n",
    "    self.fig.tight_layout(pad=3.0)\n",
    "\n",
    "    self.plots = self.plots.flatten() # to allow looping over them in single for loop\n",
    "\n",
    "class TestingPlotCallback(PlottingCallback, tf.keras.callbacks.Callback):\n",
    "  def __init__(self, steps = 5, epochs_step=10, test_data=None):\n",
    "    super(TestingPlotCallback, self).__init__(epochs_step, steps, \"Testing\")\n",
    "    \n",
    "    self.test_data = test_data\n",
    "\n",
    "    # compute the limits for x and y axes for the subplot grid\n",
    "    y_min, y_max = min(test_data[1])[0], max(test_data[1])[0]\n",
    "    yspread = y_max - y_min\n",
    "    x_min, x_max = min(test_data[0])[0], max(test_data[0])[0]\n",
    "    xspread = x_max - x_min\n",
    "    \n",
    "\n",
    "    self.lims = {\n",
    "      \"x\": (\n",
    "        floor(x_min - xspread * 0.1), \n",
    "        floor(x_max + xspread * 0.1), \n",
    "        floor(xspread * 1.2 // 5)\n",
    "      ),\n",
    "      \"y\": (\n",
    "        floor(y_min - 0.1 * yspread),\n",
    "        floor(y_max + 0.1 * yspread),\n",
    "        floor(yspread * 1.2 // 5)\n",
    "      )\n",
    "    }\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    mark = self.epochs_step - 1\n",
    "    if epoch > 0 and (epoch + 1) % self.epochs_step == 0:\n",
    "      step = epoch // mark - 1\n",
    "      test_x, test_y = self.test_data\n",
    "      ax = self.plots[step]\n",
    "    \n",
    "      # plot the expected and predicted values\n",
    "      ax.scatter(test_x, test_y, label='test', color='red')\n",
    "      ax.plot(test_x, self.model.predict(test_x), label='prediction', color='blue')\n",
    "      ax.legend(['Test', 'Pred'])\n",
    "      ax.set_title(f'Epoch: {epoch + 1}')\n",
    "\n",
    "      y_min, y_max, y_step = self.lims[\"y\"]\n",
    "      ax.set_xticks(np.arange(*(self.lims['x'])))\n",
    "      ax.set_yticks(np.arange(y_min, y_max, y_step))\n",
    "      self.fig.add_subplot(ax)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('TFX': conda)"
  },
  "interpreter": {
   "hash": "8290c4fa312f0275d52774cf1cfc50565c3a57a31ddf7b44870733d485867938"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}